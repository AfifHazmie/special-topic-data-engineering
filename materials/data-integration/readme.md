<a href="https://github.com/drshahizan/special-topic-data-engineering/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/special-topic-data-engineering" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/special-topic-data-engineering/network/members"><img src="https://img.shields.io/github/forks/drshahizan/special-topic-data-engineering" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/special-topic-data-engineering/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/special-topic-data-engineering" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/special-topic-data-engineering/issues"><img src="https://img.shields.io/github/issues/drshahizan/special-topic-data-engineering" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/special-topic-data-engineering/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/special-topic-data-engineering?color=2b9348"></a>
![](https://visitor-badge.glitch.me/badge?page_id=drshahizan/special-topic-data-engineering)

Don't forget to hit the :star: if you like this repo.

# Data Integration in Data Science

Data integration is the process of combining data from multiple sources into a unified view for analysis. This can be a complex and challenging task, but it is essential for organizations that want to make the most of their data.

There are many different tools and techniques that can be used for data integration. Some of the most common include:

* **ETL (Extract, Transform, Load)**: ETL tools extract data from source systems, transform it to make it consistent and compatible, and then load it into a target system.
* **ELT (Extract, Load, Transform)**: ELT tools extract data from source systems, load it into a target system, and then transform it as needed.
* **EAI (Enterprise Application Integration)**: EAI tools integrate data from different applications within an organization.

The type of data integration tool that is best for an organization will depend on the specific needs of the organization. For example, an organization that needs to integrate data from a variety of sources may choose to use an ETL tool, while an organization that needs to integrate data from a few applications may choose to use an EAI tool.

Data integration is an essential part of data science. By integrating data from multiple sources, organizations can gain a deeper understanding of their data and make better decisions.

## Table of Data Integration Tools

| Tool Type | Description |
|---|---|
| ETL | Extracts data from source systems, transforms it to make it consistent and compatible, and then loads it into a target system. |
| ELT | Extracts data from source systems, loads it into a target system, and then transforms it as needed. |
| EAI | Integrates data from different applications within an organization. |


## Assignment

This assignment is divided into two parts:

### Part 1: Web scraping multimedia content
You must select the appropriate website to do web scraping multimedia content. For example, you can use the [Flickr.com](flickr.md) website. Flickr is a popular photo-sharing platform that contains a vast collection of images and videos that can be scraped for data analysis purposes. Here is a suggested outline for the assignment:

#### 1. Introduction

Briefly introduce the topic of web scraping multimedia content and the importance of this type of data for research and analysis.

#### 2. Web Scraping Flickr

- Explain why Flickr is a good source for multimedia content and provide a brief overview of the site.
- Detail the web scraping process, including the tools and libraries used and any challenges that were encountered.
- Discuss the data set obtained, including metadata such as data size, file type, and other relevant information.

#### 3. Choosing a Library for Web Scraping

- Compare and contrast the available libraries for web scraping multimedia content, including Pillow and OpenCV.
- Explain the criteria used to choose the appropriate library for this project.
- Justify the final choice and explain the advantages of the chosen library.

#### 4. Storing Data in MongoDB

- Discuss the benefits of using MongoDB for storing multimedia content data.
- Explain the best way to store the data in MongoDB, including the data structure and organization.
- Provide examples of how the data can be queried and analyzed using MongoDB.

#### 5. Conclusion

- Summarize the main points of the assignment and restate the importance of web scraping multimedia content for data analysis.
- Offer suggestions for future research or analysis using the data set obtained from Flickr.

### Part 2: Web scraping text content
You need to find a website relevant to data publication content, such as the [Google Scholar](google-scholar.md) website. Google Scholar is a popular search engine for academic publications, making it an excellent source for web scraping data related to the Faculty of Computing at the University of Technology Malaysia. Here is a suggested outline for the assignment:

#### 1. Introduction
- Briefly introduce the topic of web scraping publication content and the importance of this type of data for research and analysis.

#### 2. Web Scraping Google Scholar
- Explain why Google Scholar is a good source for publication content and provide a brief overview of the site.
- Detail the web scraping process, including the tools and libraries used and any challenges that were encountered.
- Discuss the data set obtained, including metadata such as data size, file type, and other relevant information.

#### 3. Choosing a Library for Web Scraping
- Compare and contrast the available libraries for web scraping publication content, including Beautiful Soup, Scrapy, and Selenium.
- Explain the criteria used to choose the appropriate library for this project.
- Justify the final choice and explain the advantages of the chosen library.

#### 4. Storing Data in MongoDB
- Discuss the benefits of using MongoDB for storing publication content data.
- Explain the best way to store the data in MongoDB, including the data structure and organization.
- Provide examples of how the data can be queried and analyzed using MongoDB.

#### 5. Conclusion
- Summarize the main points of the assignment and restate the importance of web scraping publication content for data analysis.
- Offer suggestions for future research or analysis using the data set obtained from Google Scholar.

Overall, this write-up should demonstrate a thorough understanding of the process of web scraping publication content, as well as the tools and libraries used for this task. It should also provide a clear and detailed explanation of how the data is stored and organized in MongoDB for efficient querying and analysis.

### Others
- Collaborate effectively with your group members to complete the task.
- Ensure to send the report in **mark down** format and **source code**.
- Please submit the assignments in the submission [**Part 1**](https://github.com/drshahizan/special-topic-data-engineering/tree/main/assignment/data-scraping/submission/part1) and [**Part 2**](https://github.com/drshahizan/special-topic-data-engineering/tree/main/assignment/data-scraping/submission/part2) folder. It would be best if you create a folder using your group name.

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/special-topic-data-engineering/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

![](https://visitor-badge.glitch.me/badge?page_id=drshahizan)



