# Part 2: Web scraping text content
## Table of Content
- [Introduction](#introduction)
- [Web Scraping Google Scholar](#web-scraping-google-scholar)
- [Choosing a Library for Web Scraping](#choosing-a-library-for-web-scraping)
- [Storing Data in MongoDB](#storing-data-in-mongodb)
- [Conclusion](#conclusion)

## Introduction
> Briefly introduce the topic of web scraping publication content and the importance of this type of data for research and analysis.
> 
Web scraping text content is the process of extracting text data from websites. It is an automatic approach that uses automated software tools to extract useful raw data from web pages and can be used to obtain large amounts of data. There are many websites that are suitable to perform web scraping and extract the text content such as articles, blogs and academic papers. 

Mostly, the text data is extracted from the website that hosts academic publication. For example, Google Scholar and ResearchGate. Both of them are famous websites for publication content and these data are helpful to use in various purposes such as tracking changes in research trends, analyzing citation patterns, identifying potential research collaborators, or extracting insights for natural language processing models.

This type of data is important for research and analysis because it can provide valuable insight to the researcher after analyzing and investigating the collected data. From here, it is possible to identify new research opportunities and discover emerging trends. Therefore, this will definitely save time and resources since researchers are not required to gather data from multiple sources.

Overall, web scraping text content plays a crucial role and acts as a valuable tool for researchers and data analysts looking to extract meaningful insights from online text data.


## Web Scraping Google Scholar
- Explain why Google Scholar is a good source for publication content and provide a brief overview of the site.
- Detail the web scraping process, including the tools and libraries used and any challenges that were encountered.
- Discuss the data set obtained, including metadata such as data size, file type, and other relevant information.

## Choosing a Library for Web Scraping
- Compare and contrast the available libraries for web scraping publication content, including Beautiful Soup, Scrapy, and Selenium.
- Explain the criteria used to choose the appropriate library for this project.
- Justify the final choice and explain the advantages of the chosen library.

## Storing Data in MongoDB
- Discuss the benefits of using MongoDB for storing publication content data.
- Explain the best way to store the data in MongoDB, including the data structure and organization.
- Provide examples of how the data can be queried and analyzed using MongoDB.

## Conclusion
- Summarize the main points of the assignment and restate the importance of web scraping publication content for data analysis.
- Offer suggestions for future research or analysis using the data set obtained from Google Scholar.
